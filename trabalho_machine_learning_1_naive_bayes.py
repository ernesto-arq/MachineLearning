# -*- coding: utf-8 -*-
"""Trabalho_Machine_Learning_1_Naive_Bayes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V_tQuQvYLIBS0ka2YgQO46PX6j8T0Wfl

## **Trabalho de Machine Learning**
**Professora:** Ananda Freire

**Aluno:** Vinicius Cordeiro Nunes - 2030070

> Importação das bibliotecas

---
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""> Importação da base de dados

----
"""

data = pd.read_csv('Iris.csv')

data

"""> Visualização dos dados de estudo

-----
"""

sns.set_style("whitegrid")

print("Gráfico 1 - Altura das pétalas")

sns.FacetGrid(data, hue ="Species",
              height = 6).map(plt.scatter,
                              'SepalLengthCm',
                              'PetalLengthCm').add_legend()

print("Gráficos 2 - Largura das pétalas")
sns.FacetGrid(data, hue ="Species",
              height = 6).map(plt.scatter,
                              'SepalWidthCm',
                              'PetalWidthCm').add_legend()

"""# Escolha do Modelo de Avaliação

De acordo com os gráficos acima, podemos identificar que as classes classificadas estão seguimentadas/clusterizadas.

Uma vez visualidados os distanciamentos entre as classes da base de dados, precisamos garantir que em qualquer amostra de treinamento exista pelo menos um registro/tupla de todas as classes. Para isso, utilizaremos o **Modelo de Avaliação: VALIDAÇÃO CRUZADA**.

# Escolha das Métricas de Classificação

Agora, vamos testar as Métricas de Classificação para selecionar a que melhor se adequa aos dados de estudo.

> Importando base dados Iris do sklearn e instanciando as labels e os dados.

----
"""

from sklearn import datasets

iris = datasets.load_iris()

X_data = iris.data
y_labels = iris.target

"""> Vamos utilzar alguns Modelos constantes no pacote Naive Bayes para as predições dentro das métricas.

----
"""

from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import CategoricalNB
from sklearn.naive_bayes import ComplementNB

from sklearn import datasets
from sklearn.metrics import accuracy_score,confusion_matrix, plot_confusion_matrix,recall_score,precision_score
from sklearn.model_selection import cross_validate, cross_val_score
from sklearn.model_selection import train_test_split

"""## Testes com o Modelo de Avaliação escolhido: Validação Cruzada

*Texto em itálico*> Métricas de Classificação que testaremos em nosso estudo

----
"""

scoring = ['accuracy', 'balanced_accuracy','f1_macro','precision_macro','recall_macro']

"""> Método para facilitação de reuso

----
"""

def test_model(model):
  return cross_validate(model,X_data,y_labels,scoring=scoring,cv=3)

"""> Teste com algoritmo ComplementNB - CNB

----
"""

test_model(ComplementNB())

"""> Teste com algoritmo CategoricalNB

----
"""

test_model(CategoricalNB())

"""> Teste com algoritmo MultinomialNB

----
"""

test_model(MultinomialNB())

"""> Teste com algoritmo GaussianNB

----
"""

test_model(GaussianNB())

"""De acordo com os testes, podemos constatar que as Métricas **Acurácia** e **Recall** são as mais próximas do acerto.
Pois em todos os modelos elas se destacaram, mostrando que podem validar a predições de maneira otimizada.

# **RESULTADO**

## Modelos de Avaliação: **Validação Cruzada**
## Métricas de Classificação: **Acurácia** e **Recall**
## Modelo/Algoritmo Naive Bayes: **MultinomialNB**
"""